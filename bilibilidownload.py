import requests
import config
from pyquery import PyQuery as pq
import re
from collections import defaultdict
import json
from typing import Dict,Any,List
from loguru import logger
import os
import time

# è·å–BVå·çš„ç±»
class FetchBV:
    # ç±»åˆå§‹åŒ–ï¼Œå®šä¹‰ç›¸å…³å±æ€§
    def __init__(self,search_key:str="åŸç¥"):
        self.search_name=search_key
        self.search_url="https://search.bilibili.com/all"
        self.search_api="https://api.bilibili.com/x/web-interface/search/type"
        # keyword=åŸç¥
        # search_type=video
        # page
        # order
        self.header=config.HEADERS
        # è®¾ç½®ä»£ç†
        self.proxies = {
            "http": "http://127.0.0.1:7890",  # HTTP ä»£ç†
            "https": "http://127.0.0.1:7890",  # HTTPS ä»£ç†
        }
        # å­˜å‚¨é€šè¿‡ç›®å½•çš„åç§°
        self.bv_dir="BV"
        # å­˜å‚¨
        self.api_dir="API"
        # ç”Ÿæˆå­˜æ”¾bvæ–‡ä»¶çš„ç›®å½•
        os.path.exists(self.bv_dir) or os.makedirs(self.bv_dir)
        # ç”Ÿæˆå­˜æ”¾apiè¿”å›jsonæ–‡ä»¶çš„ç›®å½•
        os.path.exists(self.api_dir) or os.makedirs(self.api_dir)
    # åˆ—è¡¨åˆ¤æ–­æ˜¯å¦ä¸ºç©º
    def is_empty(self,target:list):
        if len(target)==0:
            return True
        else:
            return False
    # æ„é€ æ­£åˆ™è¡¨è¾¾å¼
    def construct_regular_expression(self,content:str):
        # bvå·çš„æ­£åˆ™è¡¨è¾¾å¼
        pattern_bv = re.compile(r'/(BV\w+)/')
        # titleçš„æ­£åˆ™è¡¨è¾¾å¼
        pattern_title=re.compile(r'title="(.*?)"')
        # bvå·åŒ¹é…
        bv_code=re.findall(pattern=pattern_bv,string=content)
        # titleå·åŒ¹é…
        title=re.findall(pattern=pattern_title,string=content)
        # å¦‚æœä¸ºç©ºåˆ™è®¾ç½®ä¸ºNone
        if self.is_empty(bv_code):
            return None
        else:
            bv_code=bv_code[0]
        return bv_code,title
    # è·å–vt
    def update_url_with_vt(self,url:str) -> str:
        # è·å–å½“å‰æ—¶é—´æˆ³å 8 ä½
        now = str(int(time.time() * 1000))[-8:]
        # æ‰¾ ? çš„ä½ç½®
        qs_idx = url.find("?")
        if qs_idx == -1:  # æ²¡æœ‰å‚æ•°
            url = f"{url}?vt={now}"
        elif re.search(r"vt=\d{8}", url):  # å·²æœ‰ vt å‚æ•°ï¼Œæ›¿æ¢
            url = re.sub(r"vt=\d{8}", f"vt={now}", url)
        else:  # æ²¡æœ‰ vt å‚æ•°ï¼ŒåŠ ä¸Š
            suffix = url[qs_idx + 1:]
            url = url[:qs_idx + 1] + f"vt={now}"
            if suffix:
                url = url + "&" + suffix
        return url
    # ä½¿ç”¨apiæ¥æœç´¢
    def search_video_use_api(self,page:int=1):
        # æå‰å®šä¹‰å¥½video_of_json
        videos_of_json=None
        self.page=page
        # apiçš„å‚æ•°
        params={
            "keyword":"åŸç¥",
            "search_type":"video",# å¿…å¡«å‚æ•°
            "page":page, # éå¿…å¡«å‚æ•°
            "order":"default" # æ’åˆ—æ–¹å¼
        }
        try:
            # å°è¯•å‘apiå‘é€è¯·æ±‚
            logger.info(f"å°è¯•å‘å“”å“©å“”å“©apiå‘é€è¯·æ±‚ğŸ˜˜ï¼")
            response = requests.get(url=self.search_api, params=params, headers=self.header, proxies=self.proxies)
            # å‘é€è¯·æ±‚æˆåŠŸ
            logger.info(f"è¯·æ±‚apiæˆåŠŸğŸ˜˜ï¼")
        except Exception as error:
            # å‘é€è¯·æ±‚å¤±è´¥
            logger.error(f"è¯·æ±‚apiå¤±è´¥ğŸ˜“ï¼")
            # 501ä»£è¡¨ç³»ç»Ÿå¤±è´¥
            if requests.status_codes==501:
                raise requests.RequestException(f"ç³»ç»Ÿé”™è¯¯ğŸ˜«ï¼")
            # å…¶å®ƒé”™è¯¯
            else:
                raise requests.RequestException(f"è¯·æ±‚å¤±è´¥ğŸ˜«ï¼")
        data=response.json()
        # è·å–jsonç›®æ ‡éƒ¨åˆ†
        videos_of_json=data.get("data").get("result")
        return videos_of_json
    # æœç´¢ï¼Œæ ¹æ®å…³é”®å­—æœç´¢ç›¸å…³çš„å†…å®¹
    def search_video_for_key(self,page:int=1,pagesize:int=30):
        self.page=page
        # å®šä¹‰å­˜æ”¾bvå·çš„å­—å…¸
        bv_dict=defaultdict(None)
        # æŸ¥è¯¢å‚æ•°
        params={
            "keyword":self.search_name,
            "page":page,
            # é˜²æ­¢oç­‰äºè´Ÿæ•°
            "o":(page-1)*pagesize if (page-1)*pagesize>=0 else 0,
            "single_column":0,
        }
        logger.info(f"æ­£åœ¨è·å–ç¬¬{page}é¡µçš„æ•°æ®ğŸ˜„ï¼")
        # urlåŠ å…¥vt
        url=self.update_url_with_vt(url=self.search_url)
        # å‘é€è¯·æ±‚
        try:
            response=requests.get(url=url,params=params,headers=self.header,proxies=self.proxies)
            logger.info(f"ç¬¬{page}é¡µçš„æ•°æ®è·å–æˆåŠŸğŸ˜„ï¼")
        except Exception as error:
            logger.error(f"ç¬¬{page}é¡µçš„æ•°æ®è·å–å¤±è´¥ğŸ’”ï¼")
            raise requests.RequestException(f"è¯·æ±‚å¤±è´¥ğŸ˜­ï¼")
        # è§£æè¯·æ±‚çš„ç»“æœ
        document=pq(response.text.encode("utf-8"))
        # è·å–è§†é¢‘åˆ—è¡¨
        video_list=document("div.video.i_wrapper.search-all-list div.video-list.row div.bili-video-card")
        for video_card in video_list.items():
            result=self.construct_regular_expression(video_card.html()) # ä¸€å®šéœ€è¦å°†pyqueryå¯¹è±¡è½¬åŒ–ä¸ºstr
            if result is not None:
                # å°†æ ‡é¢˜å’Œbvå·ä¸€ä¸€å¯¹åº”
                bv_dict.update({result[1][0]:result[0]})
        logger.info(f"è·å–BVå·æˆåŠŸğŸ“ºï¼")
        return bv_dict
    # å°†å­—å…¸ä¿å­˜åœ¨jsonæ–‡ä»¶é‡Œé¢
    def write_for_json(self,data:Dict[str,str],json_path:str=None):
        if json_path is None:
            json_path=os.path.join(self.bv_dir,f"{self.page}.json")
        with open(json_path,"w",encoding="utf-8") as file:
            file.write(json.dumps(data,indent=2,ensure_ascii=False))
    # apiè·å–çš„jsonï¼Œå¤„ç†å’Œå†™å…¥æ–¹å¼
    def write_for_json_api(self,data:List[Dict[str,Any]],json_path:str=None):
        # å®šä¹‰å­˜æ”¾æ•°æ®çš„åˆ—è¡¨
        video_datas=list()
        # åˆ¤æ–­json_pathæ˜¯å¦ä¸ºç©º
        if json_path is None:
            json_path=os.path.join(self.api_dir,f"{self.page}.json")
        # å¤„ç†apiè·å–çš„jsonæ•°æ®
        logger.info(f"æ­£åœ¨å¤„ç†è·å–çš„jsonæ•°æ®ğŸ¥³ï¼")
        for video_json in data:
            video_datas.append({
                "type":video_json.get("type"), # æ–‡ä»¶ç±»å‹
                "author":video_json.get("author"), # ä½œè€…
                "typename":video_json.get("typename"), # ç±»å‹
                "url":video_json.get("arcurl"), # url
                "bvid":video_json.get("bvid"), # è§†é¢‘BVå·
                "title":video_json.get("title"), # è§†é¢‘æ ‡é¢˜
                "description":video_json.get("description"), # è§†é¢‘ç®€ä»‹ï¼Œè¯¦ç»†å†…å®¹
                "tag":video_json.get("tag"), # ä½œå“æ ‡ç­¾
                "duration":video_json.get("duration"), # è§†é¢‘æŒç»­æ—¶é—´
            })
        # å°†ä¿®æ”¹ä¹‹åçš„jsonå†™å…¥
        try:
            logger.info(f"æ­£åœ¨å‘æ–‡ä»¶å†™å…¥æ•°æ®ğŸ˜˜ï¼")
            with open(json_path,"w",encoding="utf-8") as file:
                file.write(json.dumps(video_datas,ensure_ascii=False,indent=2))
            logger.info(f"å†™å…¥æˆåŠŸğŸ’•ï¼")
        except Exception as error:
            logger.error(f"å†™å…¥å¤±è´¥ğŸ˜…ï¼")
            raise Exception("å†™å…¥æ–‡ä»¶å¤±è´¥ï¼")
# ä¸‹è½½å“”å“©å“”å“©è§†é¢‘
class BilibiliDownload:
    def __init__(self,bv_number:str):
        # å®šä¹‰å±ç›¸
        self.bv_number=bv_number
    # é€šè¿‡BVå·è·å–aidã€cid
    def get_aid_cid(self,bvid):
        pass
if __name__=="__main__":
    bilibili_down=FetchBV()
    data=bilibili_down.search_video_use_api()
    bilibili_down.write_for_json_api(data)