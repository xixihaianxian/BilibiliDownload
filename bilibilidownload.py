import argparse
import requests
import config
from pyquery import PyQuery as pq
import re
from collections import defaultdict
import json
from typing import Dict,Any,List
from loguru import logger
import os
import time
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from tqdm import tqdm

# è·å–BVå·çš„ç±»
class FetchBV:
    # ç±»åˆå§‹åŒ–ï¼Œå®šä¹‰ç›¸å…³å±æ€§
    def __init__(self,search_key:str="åŸç¥"):
        self.search_name=search_key
        self.search_url="https://search.bilibili.com/all"
        self.search_api="https://api.bilibili.com/x/web-interface/search/type"
        # keyword=åŸç¥
        # search_type=video
        # page
        # order
        self.header=config.HEADERS
        # è®¾ç½®ä»£ç†ï¼Œå¦‚æœæ²¡æœ‰ä»£ç†å¯ä»¥è®¾åˆ¶ä¸ºNone
        self.proxies = {
            "http": "http://127.0.0.1:7890",  # HTTP ä»£ç†
            "https": "http://127.0.0.1:7890",  # HTTPS ä»£ç†
        }
        # å­˜å‚¨é€šè¿‡ç›®å½•çš„åç§°
        self.bv_dir="BV"
        # å­˜å‚¨
        self.api_dir="API"
        # ç”Ÿæˆå­˜æ”¾bvæ–‡ä»¶çš„ç›®å½•
        os.path.exists(self.bv_dir) or os.makedirs(self.bv_dir)
        # ç”Ÿæˆå­˜æ”¾apiè¿”å›jsonæ–‡ä»¶çš„ç›®å½•
        os.path.exists(self.api_dir) or os.makedirs(self.api_dir)
    # åˆ—è¡¨åˆ¤æ–­æ˜¯å¦ä¸ºç©º
    def is_empty(self,target:list):
        if len(target)==0:
            return True
        else:
            return False
    # æ„é€ æ­£åˆ™è¡¨è¾¾å¼
    def construct_regular_expression(self,content:str):
        # bvå·çš„æ­£åˆ™è¡¨è¾¾å¼
        pattern_bv = re.compile(r'/(BV\w+)/')
        # titleçš„æ­£åˆ™è¡¨è¾¾å¼
        pattern_title=re.compile(r'title="(.*?)"')
        # bvå·åŒ¹é…
        bv_code=re.findall(pattern=pattern_bv,string=content)
        # titleå·åŒ¹é…
        title=re.findall(pattern=pattern_title,string=content)
        # å¦‚æœä¸ºç©ºåˆ™è®¾ç½®ä¸ºNone
        if self.is_empty(bv_code):
            return None
        else:
            bv_code=bv_code[0]
        return bv_code,title
    # è·å–vt
    def update_url_with_vt(self,url:str) -> str:
        # è·å–å½“å‰æ—¶é—´æˆ³å 8 ä½
        now = str(int(time.time() * 1000))[-8:]
        # æ‰¾ ? çš„ä½ç½®
        qs_idx = url.find("?")
        if qs_idx == -1:  # æ²¡æœ‰å‚æ•°
            url = f"{url}?vt={now}"
        elif re.search(r"vt=\d{8}", url):  # å·²æœ‰ vt å‚æ•°ï¼Œæ›¿æ¢
            url = re.sub(r"vt=\d{8}", f"vt={now}", url)
        else:  # æ²¡æœ‰ vt å‚æ•°ï¼ŒåŠ ä¸Š
            suffix = url[qs_idx + 1:]
            url = url[:qs_idx + 1] + f"vt={now}"
            if suffix:
                url = url + "&" + suffix
        return url
    # ä½¿ç”¨apiæ¥æœç´¢
    def search_video_use_api(self,page:int=1,order:str="default"):
        # æå‰å®šä¹‰å¥½video_of_json
        videos_of_json=None
        self.page=page
        # apiçš„å‚æ•°
        params={
            "keyword":"åŸç¥",
            "search_type":"video",# å¿…å¡«å‚æ•°
            "page":page, # éå¿…å¡«å‚æ•°
            "order":order # æ’åˆ—æ–¹å¼
        }
        try:
            # å°è¯•å‘apiå‘é€è¯·æ±‚
            logger.info(f"å°è¯•å‘å“”å“©å“”å“©apiå‘é€è¯·æ±‚ğŸ˜˜ï¼")
            response = requests.get(url=self.search_api, params=params, headers=self.header, proxies=self.proxies)
            # å‘é€è¯·æ±‚æˆåŠŸ
            logger.info(f"è¯·æ±‚apiæˆåŠŸğŸ˜˜ï¼")
        except Exception as error:
            # å‘é€è¯·æ±‚å¤±è´¥
            logger.error(f"è¯·æ±‚apiå¤±è´¥ğŸ˜“ï¼")
            # 501ä»£è¡¨ç³»ç»Ÿå¤±è´¥
            if requests.status_codes==-501:
                raise requests.RequestException(f"ç³»ç»Ÿé”™è¯¯ğŸ˜«ï¼")
            # å…¶å®ƒé”™è¯¯
            else:
                raise requests.RequestException(f"è¯·æ±‚å¤±è´¥ğŸ˜«ï¼")
        data=response.json()
        # è·å–jsonç›®æ ‡éƒ¨åˆ†
        videos_of_json=data.get("data").get("result")
        return videos_of_json
    # æœç´¢ï¼Œæ ¹æ®å…³é”®å­—æœç´¢ç›¸å…³çš„å†…å®¹
    def search_video_for_key(self,page:int=1,pagesize:int=30):
        self.page=page
        # å®šä¹‰å­˜æ”¾bvå·çš„å­—å…¸
        bv_dict=defaultdict(None)
        # æŸ¥è¯¢å‚æ•°
        params={
            "keyword":self.search_name,
            "page":page,
            # é˜²æ­¢oç­‰äºè´Ÿæ•°
            "o":(page-1)*pagesize if (page-1)*pagesize>=0 else 0,
            "single_column":0,
        }
        logger.info(f"æ­£åœ¨è·å–ç¬¬{page}é¡µçš„æ•°æ®ğŸ˜„ï¼")
        # urlåŠ å…¥vt
        url=self.update_url_with_vt(url=self.search_url)
        # å‘é€è¯·æ±‚
        try:
            response=requests.get(url=url,params=params,headers=self.header,proxies=self.proxies)
            logger.info(f"ç¬¬{page}é¡µçš„æ•°æ®è·å–æˆåŠŸğŸ˜„ï¼")
        except Exception as error:
            logger.error(f"ç¬¬{page}é¡µçš„æ•°æ®è·å–å¤±è´¥ğŸ’”ï¼")
            raise requests.RequestException(f"è¯·æ±‚å¤±è´¥ğŸ˜­ï¼")
        # è§£æè¯·æ±‚çš„ç»“æœ
        document=pq(response.text.encode("utf-8"))
        # è·å–è§†é¢‘åˆ—è¡¨
        video_list=document("div.video.i_wrapper.search-all-list div.video-list.row div.bili-video-card")
        for video_card in video_list.items():
            result=self.construct_regular_expression(video_card.html()) # ä¸€å®šéœ€è¦å°†pyqueryå¯¹è±¡è½¬åŒ–ä¸ºstr
            if result is not None:
                # å°†æ ‡é¢˜å’Œbvå·ä¸€ä¸€å¯¹åº”
                bv_dict.update({result[1][0]:result[0]})
        logger.info(f"è·å–BVå·æˆåŠŸğŸ“ºï¼")
        return bv_dict
    # å°†å­—å…¸ä¿å­˜åœ¨jsonæ–‡ä»¶é‡Œé¢
    def write_for_json(self,data:Dict[str,str],json_path:str=None):
        if json_path is None:
            json_path=os.path.join(self.bv_dir,f"{self.page}.json")
        with open(json_path,"w",encoding="utf-8") as file:
            file.write(json.dumps(data,indent=2,ensure_ascii=False))
    # apiè·å–çš„jsonï¼Œå¤„ç†å’Œå†™å…¥æ–¹å¼
    def write_for_json_api(self,data:List[Dict[str,Any]],json_path:str=None):
        # å®šä¹‰å­˜æ”¾æ•°æ®çš„åˆ—è¡¨
        video_datas=list()
        # åˆ¤æ–­json_pathæ˜¯å¦ä¸ºç©º
        if json_path is None:
            json_path=os.path.join(self.api_dir,f"{self.page}.json")
        # å¤„ç†apiè·å–çš„jsonæ•°æ®
        logger.info(f"æ­£åœ¨å¤„ç†è·å–çš„jsonæ•°æ®ğŸ¥³ï¼")
        for video_json in data:
            video_datas.append({
                "type":video_json.get("type"), # æ–‡ä»¶ç±»å‹
                "author":video_json.get("author"), # ä½œè€…
                "typename":video_json.get("typename"), # ç±»å‹
                "url":video_json.get("arcurl"), # url
                "bvid":video_json.get("bvid"), # è§†é¢‘BVå·
                "title":video_json.get("title"), # è§†é¢‘æ ‡é¢˜
                "description":video_json.get("description"), # è§†é¢‘ç®€ä»‹ï¼Œè¯¦ç»†å†…å®¹
                "tag":video_json.get("tag"), # ä½œå“æ ‡ç­¾
                "duration":video_json.get("duration"), # è§†é¢‘æŒç»­æ—¶é—´
            })
        # å°†ä¿®æ”¹ä¹‹åçš„jsonå†™å…¥
        try:
            logger.info(f"æ­£åœ¨å‘æ–‡ä»¶å†™å…¥æ•°æ®ğŸ˜˜ï¼")
            with open(json_path,"w",encoding="utf-8") as file:
                file.write(json.dumps(video_datas,ensure_ascii=False,indent=2))
            logger.info(f"å†™å…¥æˆåŠŸğŸ’•ï¼")
        except Exception as error:
            logger.error(f"å†™å…¥å¤±è´¥ğŸ˜…ï¼")
            raise Exception("å†™å…¥æ–‡ä»¶å¤±è´¥ï¼")
# ä¸‹è½½å“”å“©å“”å“©è§†é¢‘
class BilibiliDownload:
    def __init__(self,bv_number:str,max_retries:int=3):
        # å®šä¹‰å±ç›¸
        self.bv_number=bv_number
        self.aid_cid_api="https://api.bilibili.com/x/web-interface/view"
        self.download_url="https://api.bilibili.com/x/player/playurl"
        self.headers=config.HEADERS
        # è®¾ç½®ä»£ç†ï¼Œå¦‚æœä»£ç†è®¾ç½®ä¸ºNone
        self.proxies = {
            "http": "http://127.0.0.1:7890",  # HTTP ä»£ç†
            "https": "http://127.0.0.1:7890",  # HTTPS ä»£ç†
        }
        # self.proxies=None
        # åˆ›å»ºå­˜æ”¾ä»bvé‚£è·å–çš„ä¿¡æ¯çš„ç›®å½•
        self.video_information_dir="information"
        os.path.exists(self.video_information_dir) or os.makedirs(self.video_information_dir)
        # åˆ›å»ºè§†é¢‘å­˜æ”¾çš„ç›®å½•
        self.video_dir = "downloads"
        os.path.exists(self.video_dir) or os.makedirs(self.video_dir)
        # é‡è¯•æ¬¡æ•°
        self.max_retries=max_retries
        # è®¾ç½®é‡è¯•æœºåˆ¶
        self.retries=Retry(
            total=max_retries, # è®¾ç½®é‡è¯•æ¬¡æ•°
            backoff_factor=1, # é‡è¯•é—´éš”
            status_forcelist=[500, 502, 503, 504], # é‡è§è¿™äº›çŠ¶æ€ç çš„æ—¶å€™é‡è¯•
            allowed_methods=["GET"] # å…è®¸é‡è¯•çš„è¯·æ±‚æ–¹å¼
        )
    # å°†åè®®å’Œé€‚é…å™¨ç»‘å®š
    def bind_session(self):
        session=requests.Session()
        session.mount(prefix="http://",adapter=HTTPAdapter(max_retries=self.retries))
        session.mount(prefix="https://",adapter=HTTPAdapter(max_retries=self.retries))
        return session
    # é€šè¿‡BVå·è·å–aidã€cid
    def get_aid_cid(self):
        # å®šä¹‰å­˜æ”¾æ•°æ®çš„å­—å…¸
        data=defaultdict(None)
        # ä½¿ç”¨sessionä¿ç•™è¯·æ±‚ä¿¡æ¯
        self.session=requests.Session()
        params={
            "bvid":self.bv_number,
        }
        # å‘apiå‘é€è¯·æ±‚ï¼Œè·å–aidï¼Œcid
        try:
            logger.info(f"æ­£åœ¨è·å–aid,cidğŸ’ª!")
            response=self.session.get(url=self.aid_cid_api,params=params,headers=self.headers,proxies=self.proxies)
            logger.info(f"è·å–åˆ°ä¸aidï¼Œcidç›¸å…³çš„json")
        except Exception as error:
            logger.error(f"è¯·æ±‚apiå¤±è´¥ğŸ˜­ï¼")
            raise requests.RequestException("å‘apiå‘é€è¯·æ±‚å¤±è´¥ğŸ˜­ï¼")
        # è‹¥è¯·æ±‚æˆåŠŸï¼Œå¤„ç†ç›¸å…³çš„jsonï¼Œä»è€Œè·å–aidï¼Œcid
        aid_cid_json=response.json()
        state_code=aid_cid_json.get("code")
        # åˆ¤æ–­è¿”å›çš„å†…å®¹æ˜¯å¦æœ‰é—®é¢˜
        if state_code!=0:
            logger.error(f"è¯·æ±‚çš„å†…å®¹æ˜¯æ— æ•ˆçš„âŒï¼")
            raise ValueError(f"è¿”å›çš„jsonå†…å®¹æ˜¯æ— æ•ˆçš„ï¼")
        else:
            # è·å–aid
            data.update({"aid":aid_cid_json.get("data").get("aid")})
            # è·å–cid
            data.update({"cid":aid_cid_json.get("data").get("cid")})
            # è·å–title
            data.update({"title":aid_cid_json.get("data").get("title")})
            # è·å–è§†é¢‘è¯¦æƒ…
            data.update({"desc":aid_cid_json.get("data").get("desc")})
        file_name=os.path.join(self.video_information_dir,f"{data.get('title')}.json")
        # å°†æ•°æ®å†™å…¥æ–‡ä»¶
        try:
            with open(file_name,"w",encoding="utf-8") as file:
                file.write(json.dumps(data,indent=2,ensure_ascii=False))
            logger.info(f"è§†é¢‘çš„ç›¸å…³ä¿¡æ¯å·²ç»æˆåŠŸå†™å…¥jsonæ–‡ä»¶ğŸ‘ï¼")
            self.title=data.get("title")
        except OSError as error:
            # æ–‡ä»¶åæ ¼å¼é”™è¯¯çš„æŠ¥é”™
            logger.warning(f"{data.get('title')}.json,æ–‡ä»¶åæ ¼å¼é”™è¯¯âŒï¼")
            # ä½¿ç”¨æ—¶é—´æˆ³æ¥å®šä¹‰æ–‡ä»¶å
            timestamp=time.strftime("%Y%m%d%H%M%S", time.localtime())
            file_name=os.path.join(self.video_information_dir,f"{timestamp}.json")
            with open(file_name,"w",encoding="utf-8") as file:
                file.write(json.dumps(data,indent=2,ensure_ascii=False))
            logger.info(f"è§†é¢‘çš„ç›¸å…³ä¿¡æ¯å·²ç»æˆåŠŸå†™å…¥jsonæ–‡ä»¶ğŸ‘ï¼")
            self.title=timestamp
        except Exception as error:
            logger.error(f"æ–‡ä»¶å†™å…¥å‡ºç°é”™è¯¯ğŸ’”ï¼")
            raise Exception("æ–‡ä»¶å†™å…¥é”™è¯¯ï¼")
        return data
    # è·å–çœŸå®çš„ä¸‹è½½é“¾æ¥
    def get_download_url(self,aid: int, cid: int, quality: int = 0):
        # å®šä¹‰å‚æ•°
        params={
            "avid":aid,
            "cid":cid,
            "qn":quality,
        }
        self.headers.update({"Referer": "https://www.bilibili.com"})
        logger.info(f"æ­£åœ¨å‘bilibiliè¯·æ±‚è§†é¢‘ğŸ’ªï¼")
        response=requests.get(url=self.download_url,params=params,proxies=self.proxies,headers=self.headers)
        state_code=response.json().get("code")
        if state_code==-400:
            logger.error(f"è¯·æ±‚å¤±è´¥ğŸ’”ï¼")
            raise requests.RequestException(f"è¯·æ±‚å¤±è´¥ğŸ˜­ï¼")
        elif state_code==-404:
            logger.error(f"æ²¡æœ‰è¿™ä¸ªè§†é¢‘ğŸ¤”ï¼")
            raise requests.RequestException(f"æ²¡æœ‰è¿™ä¸ªè§†é¢‘ğŸ¤”ï¼")
        durl=response.json().get("data").get("durl")[0].get("url")
        return durl
    # ä¸‹è½½è§†é¢‘
    def download_video(self,url: str=None, file_name: str=None, save_dir: str = "./downloads"):
        r"""
        :param url: è§†é¢‘çš„çœŸå®URL
        :param file_name: è§†é¢‘ä¸‹è½½å­˜æ”¾çš„æ–‡ä»¶åï¼ï¼ï¼ˆæ–‡ä»¶åæ˜¯è¦å¼€åç¼€ï¼ï¼ï¼ï¼ğŸ‘€ï¼‰
        :param save_dir: è§†é¢‘å­˜æ”¾çš„ç›®å½•ï¼
        :return: None
        """
        os.makedirs(save_dir, exist_ok=True)
        # åˆ¤æ–­file_nameæ˜¯å¦ä¸ºNoneï¼Œå¦‚æœä¸æ˜¯Noneç›´æ¥åˆ›å»ºæ–‡ä»¶è·¯å¾„
        if file_name is not None:
            file_path = os.path.join(save_dir, file_name)
        # å¦‚æœNoneï¼Œåˆ™
        else:
            file_name = self.title
            file_path=os.path.join(save_dir,f"{file_name}.mp4")
        # å®šä¹‰è®¡æ•°å™¨
        attempt=0
        # è·å–session
        session=self.bind_session()
        while attempt<self.max_retries:
            try:
                with session.get(url=url,stream=True,headers=self.headers,proxies=self.proxies) as response:
                    # éªŒè¯çŠ¶æ€ç ï¼Œå¦‚æœçŠ¶æ€ä¸ç¬¦åˆè¦æ±‚å°±ä¼šè‡ªåŠ¨æŠ¥é”™ï¼
                    response.raise_for_status()
                    # è·å–è§†é¢‘çš„å¤§å°
                    video_size=int(response.headers.get("Content-Length"))
                    with open(file_path,"wb") as file,tqdm(
                        total=video_size, # è®¾ç½®æ€»é•¿åº¦
                        unit="B",
                        unit_divisor=1024,
                        unit_scale=True
                    ) as bar: # ä¸‹è½½è¿›åº¦æ¡
                        for chunk in response.iter_content(chunk_size=1024):
                            if chunk:
                                file.write(chunk)
                                bar.update(1024)
                logger.info(f"download successfulğŸ‘Œ!Please check {file_path}")
                exit(0) # æ­£å¸¸é€€å‡º
            except requests.exceptions.RequestException as error:
                attempt+=1
                logger.warning(f"ä¸‹è½½é”™è¯¯ï¼Œå°è¯•ç¬¬{attempt}/{self.max_retries}æ¬¡ä¸‹è½½â™»ï¸ï¼")
        raise Exception(f"å¤šæ¬¡ä¸‹è½½å¤±è´¥ï¼Œç»“æŸä¸‹è½½ğŸ˜¡ï¼")
# è®¾ç½®æŒ‡ä»¤
def main():
    parser=argparse.ArgumentParser(description=f"Fetch Bilibili videoğŸ˜!")
    # æ˜¯å¦è·å–BVå·
    parser.add_argument("--fetchBV","-fb",dest="fetch_bv",action="store_ture",help="determine whether to obtain the BV number")
    # å…³é”®å­—å¡«å†™
    parser.add_argument("--key","-k",dest="key",default="åŸç¥",help="search keyword",type=str)
    # è·å–BVå·çš„æ–¹å¼
    parser.add_argument("--method","-m",dest="method",choices=["search","api"],help="ways to obtain a BV number",type=str)
    # é¡µç 
    parser.add_argument("--page","-p",dest="page",default=1,type=int,help="page number")
    # ä¿®æ”¹æ’åˆ—æ–¹å¼
    parser.add_argument("--order","-o",type=str,default="default",help="sorting method",dest="order")
    # æ˜¯å¦éœ€è¦ä¿å­˜
    parser.add_argument("--save","-s",dest="save",choices=[True,False],default=False,type=bool,help="Do you need to save the obtained JSON?")
    # å­˜æ”¾jsonæ–‡ä»¶çš„æ–‡ä»¶å
    parser.add_argument("--filename","-fn",default=None,type=str,dest="filename",help="The filename for saving the JSON file")
    # è¾“å…¥BVå·
    parser.add_argument("--BV","-bv",dest="bv",type=str,help="BV number")
    # æœ€å¤§å°è¯•æ¬¡æ•°
    parser.add_argument("--maxretries","-mt",type=int,default=3,dest="max_retries",help="Maximum number of attempts")
    # aidå·
    parser.add_argument("--aid","-a",type=int,dest="aid",help="aid number")
    # cidå·
    parser.add_argument("--cid","-c",type=int,dest="cid",help="cid number")
    # æ¸…æ™°åº¦
    parser.add_argument("--quality","-q",type=int,default=0,dest="quality",help="quality")
    # å­˜æ”¾è§†é¢‘çš„ç›®å½•
    parser.add_argument("--savedir","-sd",type=str,default="./downloads",dest="savedir",help="Directory for storing videos")
    # å­˜æ”¾è§†é¢‘çš„æ–‡ä»¶åç§°
    parser.add_argument("--videoname","-vn",dest="videoname",type="str",default=None,help="The file name for storing videos")
if __name__=="__main__":
    bilibili_download=BilibiliDownload(bv_number="BV1jhJCzSEa7")
    data=bilibili_download.get_aid_cid()
    url=bilibili_download.get_download_url(aid=data.get("aid"),cid=data.get("cid"))
    bilibili_download.download_video(url=url,file_name="1.mp4")